<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><title>Python: module vector_space</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head><body bgcolor="#f0f0f8">

<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="heading">
<tr bgcolor="#7799ee">
<td valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial">&nbsp;<br><big><big><strong>vector_space</strong></big></big></font></td
><td align=right valign=bottom
><font color="#ffffff" face="helvetica, arial"><a href=".">index</a><br><a href="file:d%3A%5Cplagiarism-checker%5Cvector_space.py">d:\plagiarism-checker\vector_space.py</a></font></td></tr></table>
    <p></p>
<p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#aa55cc">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Modules</strong></big></font></td></tr>
    
<tr><td bgcolor="#aa55cc"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><table width="100%" summary="list"><tr><td width="25%" valign=top><a href="checker.html">checker</a><br>
</td><td width="25%" valign=top><a href="nltk.html">nltk</a><br>
</td><td width="25%" valign=top><a href="os.html">os</a><br>
</td><td width="25%" valign=top><a href="pickle.html">pickle</a><br>
</td></tr></table></td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#55aa55">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Data</strong></big></font></td></tr>
    
<tr><td bgcolor="#55aa55"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><strong>checker_obj</strong> = &lt;checker.Checker object&gt;<br>
<strong>corpus</strong> = ['g0pA_taska.txt', 'g0pA_taskb.txt', 'g0pA_taskc.txt', 'g0pA_taskd.txt', 'g0pA_taske.txt', 'g0pB_taska.txt', 'g0pB_taskb.txt', 'g0pB_taskc.txt', 'g0pB_taskd.txt', 'g0pB_taske.txt', 'g0pC_taska.txt', 'g0pC_taskb.txt', 'g0pC_taskc.txt', 'g0pC_taskd.txt', 'g0pC_taske.txt', 'g0pD_taska.txt', 'g0pD_taskb.txt', 'g0pD_taskc.txt', 'g0pD_taskd.txt', 'g0pD_taske.txt', ...]<br>
<strong>corpus_path</strong> = 'D:/Plagiarism-Checker/corpus-original'<br>
<strong>count</strong> = 5<br>
<strong>data_dict</strong> = {'g0pA_taska.txt': {'add': 1, 'added': 1, 'adding': 1, 'allowing': 1, 'basic': 2, 'called': 1, 'child': 2, 'class': 5, 'classes': 8, 'concept': 1, ...}, 'g0pA_taskb.txt': {'0': 1, '10': 1, 'actual': 1, 'algorithm': 4, 'algorithms': 1, 'also': 2, 'analysis': 1, 'applied': 1, 'ask': 1, 'assigns': 3, ...}, 'g0pA_taskc.txt': {'accurately': 1, 'algebraic': 1, 'also': 2, 'appear': 1, 'appears': 1, 'application': 1, 'associated': 1, 'badly': 1, 'best': 1, 'calculating': 1, ...}, 'g0pA_taskd.txt': {'according': 1, 'agree': 1, 'aims': 1, 'also': 1, 'amongst': 1, 'around': 1, 'assign': 2, 'assigned': 1, 'bayes': 6, 'bayesian': 1, ...}, 'g0pA_taske.txt': {'1': 1, '2': 1, '3': 1, '4': 1, 'affect': 1, 'algorithm': 1, 'also': 1, 'always': 1, 'bottom': 2, 'caching': 1, ...}, 'g0pB_taska.txt': {'allows': 1, 'also': 1, 'another': 1, 'apply': 1, 'available': 5, 'basic': 1, 'block': 4, 'building': 3, 'buildings': 2, 'certain': 1, ...}, 'g0pB_taskb.txt': {'0': 1, '85': 1, 'actual': 2, 'algorithm': 2, 'apply': 1, 'back': 1, 'backlinks': 1, 'based': 1, 'basically': 1, 'bored': 1, ...}, 'g0pB_taskc.txt': {'algebraic': 1, 'also': 1, 'angles': 1, 'appear': 1, 'application': 1, 'associated': 1, 'assumptions': 1, 'best': 1, 'calculated': 1, 'chosen': 1, ...}, 'g0pB_taskd.txt': {'account': 1, 'acts': 1, 'also': 1, 'arranging': 1, 'b': 16, 'bayes': 5, 'begin': 1, 'called': 1, 'certain': 1, 'combining': 1, ...}, 'g0pB_taske.txt': {'1': 1, '1940s': 1, '1953': 1, '2': 1, '3': 1, 'adjacent': 1, 'another': 1, 'bellman': 1, 'best': 2, 'break': 1, ...}, ...}<br>
<strong>data_keys</strong> = dict_keys(['g0pA_taska.txt', 'g0pA_taskb.txt', '..._taskc.txt', 'orig_taskd.txt', 'orig_taske.txt'])<br>
<strong>data_pickle</strong> = &lt;_io.BufferedReader name='data.txt'&gt;<br>
<strong>doc</strong> = 'orig_taske.txt'<br>
<strong>doc_content</strong> = r"b'In mathematics and computer science, dynamic p...roblems we know that we\'ll need in advance.\r\n'"<br>
<strong>doc_file</strong> = &lt;_io.BufferedReader name='D:/Plagiarism-Checker/corpus-original/orig_taske.txt'&gt;<br>
<strong>doc_path</strong> = 'D:/Plagiarism-Checker/corpus-original/orig_taske.txt'<br>
<strong>doc_tokens</strong> = ["b'In", 'mathematics', 'and', 'computer', 'science', ',', 'dynamic', 'programming', 'is', 'a', 'method', 'of', 'solving', 'problems', 'that', 'exhibit', 'the', 'properties', 'of', 'overlapping', ...]<br>
<strong>file_path</strong> = r'D:\Plagiarism-Checker\corpus-original\orig_taskb.txt'<br>
<strong>filtered_input</strong> = ['b', 'PageRank', 'link', 'analysis', 'algorithm', 'used', 'Google', 'Internet', 'search', 'engine', 'assigns', 'numerical', 'weighting', 'element', 'hyperlinked', 'set', 'documents', 'World', 'Wide', 'Web', ...]<br>
<strong>i</strong> = 4<br>
<strong>input_data</strong> = r"b'PageRank is a link analysis algorithm used by ...CLEVER project, and the TrustRank algorithm.\r\n'"<br>
<strong>input_file</strong> = &lt;_io.BufferedReader name='D:\\Plagiarism-Checker\\corpus-original\\orig_taskb.txt'&gt;<br>
<strong>input_freq</strong> = {'0': 1, '1': 1, '10': 1, '2005': 1, '285': 1, '336': 1, '6': 1, '8': 1, '999': 1, 'A': 4, ...}<br>
<strong>input_tokens</strong> = ['b', 'PageRank', 'is', 'a', 'link', 'analysis', 'algorithm', 'used', 'by', 'the', 'Google', 'Internet', 'search', 'engine', 'that', 'assigns', 'a', 'numerical', 'weighting', 'to', ...]<br>
<strong>length</strong> = [215, 234, 255, 187, 213, 329, 256, 353, 253, 261, 218, 215, 206, 149, 164, 208, 87, 193, 43, 105, ...]<br>
<strong>score_key</strong> = 'orig_taske.txt'<br>
<strong>score_keys</strong> = dict_keys(['g0pA_taska.txt', 'g0pA_taskb.txt', '..._taskc.txt', 'orig_taskd.txt', 'orig_taske.txt'])<br>
<strong>scores</strong> = {'g0pA_taska.txt': 0.023713656024838894, 'g0pA_taskb.txt': 0.7355600105386113, 'g0pA_taskc.txt': 0.0810756962125042, 'g0pA_taskd.txt': 0.025570116483920588, 'g0pA_taske.txt': 0.04161621389976658, 'g0pB_taska.txt': 0.024882648072022773, 'g0pB_taskb.txt': 0.7147521338506132, 'g0pB_taskc.txt': 0.060787107128778814, 'g0pB_taskd.txt': 0.08852330568131117, 'g0pB_taske.txt': 0.026496189125495694, ...}<br>
<strong>sorted_score</strong> = 'g2pC_taskb.txt'<br>
<strong>sorted_score_keys</strong> = dict_keys(['orig_taskb.txt', 'g1pB_taskb.txt', '..._taske.txt', 'g3pB_taske.txt', 'g3pA_taska.txt'])<br>
<strong>sorted_scores</strong> = {'g0pA_taska.txt': 0.023713656024838894, 'g0pA_taskb.txt': 0.7355600105386113, 'g0pA_taskc.txt': 0.0810756962125042, 'g0pA_taskd.txt': 0.025570116483920588, 'g0pA_taske.txt': 0.04161621389976658, 'g0pB_taska.txt': 0.024882648072022773, 'g0pB_taskb.txt': 0.7147521338506132, 'g0pB_taskc.txt': 0.060787107128778814, 'g0pB_taskd.txt': 0.08852330568131117, 'g0pB_taske.txt': 0.026496189125495694, ...}<br>
<strong>stop_words</strong> = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", "you've", "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', ...]<br>
<strong>stopwords</strong> = &lt;WordListCorpusReader in 'C:\\Users\\Naren\\AppData\\Roaming\\nltk_data\\corpora\\stopwords'&gt;<br>
<strong>temp_term</strong> = {'1': 2, '1940s': 1, '1953': 1, '2': 2, '3': 1, 'acceptable': 1, 'action': 2, 'adjacent': 1, 'advance': 1, 'algorithm': 1, ...}<br>
<strong>term_key</strong> = 'word'<br>
<strong>term_keys</strong> = dict_keys(['1', '1940s', '1953', '2', '3', 'acce...ertex', 'vertices', 'waste', 'whenever', 'word'])<br>
<strong>tfidf</strong> = 0.6020599913279623<br>
<strong>tfidf_dict</strong> = {('0', 'g0pA_taskb.txt'): 0.7781512503836435, ('0', 'g0pB_taskb.txt'): 0.7781512503836435, ('0', 'g1pA_taskb.txt'): 0.7781512503836435, ('0', 'g1pD_taskb.txt'): 4.668907502301861, ('0', 'g1pD_taskc.txt'): 0.7781512503836435, ('0', 'g1pD_taskd.txt'): 0.7781512503836435, ('0', 'g2pA_taskb.txt'): 0.7781512503836435, ('0', 'g2pA_taskd.txt'): 2.3344537511509307, ('0', 'g2pB_taskb.txt'): 0.7781512503836435, ('0', 'g2pC_taskd.txt'): 2.3344537511509307, ...}<br>
<strong>tfidf_keys</strong> = dict_keys([('add', 'g0pA_taska.txt'), ('added', ..., 'orig_taske.txt'), ('word', 'orig_taske.txt')])<br>
<strong>tfidf_pickle</strong> = &lt;_io.BufferedReader name='tfidf.txt'&gt;<br>
<strong>tokenizer</strong> = RegexpTokenizer(pattern='\\w+', gaps=False, disc..., flags=&lt;RegexFlag.UNICODE|DOTALL|MULTILINE: 56&gt;)<br>
<strong>top_doc_path</strong> = 'D:/Plagiarism-Checker/corpus-original/g2pC_taskb.txt'<br>
<strong>top_doc_scores</strong> = 0.7360069808073468<br>
<strong>top_docs</strong> = ['orig_taskb.txt', 'g1pB_taskb.txt', 'g3pA_taskb.txt', 'g4pE_taskb.txt', 'g2pC_taskb.txt']</td></tr></table>
</body></html>